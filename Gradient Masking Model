Gradient Masking
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical


def load_and_preprocess_data():
    # Load MNIST dataset
    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
   
    # Normalize pixel values to be between 0 and 1
    train_images, test_images = train_images / 255.0, test_images / 255.0
   
    # Convert images to RGB format
    train_images = tf.image.grayscale_to_rgb(tf.image.resize(train_images[..., tf.newaxis], (32, 32)))
    test_images = tf.image.grayscale_to_rgb(tf.image.resize(test_images[..., tf.newaxis], (32, 32)))
   
    # Convert labels to one-hot encoded format
    train_labels = to_categorical(train_labels, num_classes=10)
    test_labels = to_categorical(test_labels, num_classes=10)
   
    return (train_images, train_labels), (test_images, test_labels)


def build_resnet():
    model_input = layers.Input(shape=(32, 32, 3))
   
    x = layers.Conv2D(32, (3, 3), activation='relu')(model_input)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2))(x)
   
    x = layers.Conv2D(64, (3, 3), activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2))(x)


    x = layers.Conv2D(128, (3, 3), activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.MaxPooling2D((2, 2))(x)
   
    x = layers.GlobalAveragePooling2D()(x)
   
    x = layers.Dense(256, activation='relu')(x)
    x = layers.Dropout(0.25)(x)
   
    predictions = layers.Dense(10, activation='softmax')(x)
   
    model = models.Model(inputs=model_input, outputs=predictions)
    return model


# Define FGSM attack
def fgsm_attack(model, x, y_true, epsilon):
    loss_object = tf.keras.losses.CategoricalCrossentropy()
    input_data = tf.convert_to_tensor(x)
    with tf.GradientTape() as tape:
        tape.watch(input_data)
        prediction = model(input_data)
        loss = loss_object(y_true, prediction)
    gradient = tape.gradient(loss, input_data)
    x_adv = input_data + epsilon * tf.sign(gradient)
    x_adv = tf.clip_by_value(x_adv, 0, 1)
    return x_adv


@tf.function
def train_step(model, images, labels, batch_size, accuracy_metric, apply_gradient_masking=True):
    with tf.GradientTape() as tape:
        predictions = model(images)
        loss = tf.keras.losses.categorical_crossentropy(labels, predictions)


    accuracy = accuracy_metric(labels, predictions)


    gradients = tape.gradient(loss, model.trainable_variables)
    masked_gradients = [tf.where(tf.math.is_finite(grad), grad, tf.zeros_like(grad)) for grad in gradients]


    # Apply the masked gradients to update the model variables
    model.optimizer.apply_gradients(zip(masked_gradients, model.trainable_variables))
    model_type = 'With Gradient Masking'


    return accuracy


# Load and preprocess data
(train_images, train_labels), (test_images, test_labels) = load_and_preprocess_data()


# Create and compile the model without gradient masking for 2 epochs
model_without_masking = build_resnet()
model_without_masking.compile(optimizer='adam',
                              loss='categorical_crossentropy',
                              metrics=['accuracy'])


# Create CategoricalAccuracy metric outside tf.function
accuracy_metric = tf.keras.metrics.CategoricalAccuracy()


# Train the model without gradient masking for 2 epochs
epochs_regular = 5
epochs = 2
batch_size = 256
resnet_model = build_resnet()
resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


# Train and evaluate the model before adversarial training
print("Training and evaluating the ResNet Model before adversarial training:")
history = resnet_model.fit(train_images, train_labels, epochs=epochs_regular, batch_size=batch_size, verbose=1)
test_loss, test_accuracy = resnet_model.evaluate(test_images, test_labels, verbose=0)
print(f"Test accuracy of the ResNet Model before adversarial training: {test_accuracy}")


# Save the entire model after regular training
model_file_path = r'C:\\Users\\eyian\\OneDrive\\Desktop\\another_model.h5'
resnet_model.save(model_file_path)


# Load the saved model for adversarial training
loaded_model = tf.keras.models.load_model(model_file_path)


# Apply gradient masking to the loaded model for 2 epochs
for epoch in range(epochs):
    print(f"Epoch {epoch + 1}/{epochs}")
    for batch_start in range(0, len(train_images), batch_size):
        batch_images = train_images[batch_start:batch_start + batch_size]
        batch_labels = train_labels[batch_start:batch_start + batch_size]
        accuracy = train_step(loaded_model, batch_images, batch_labels, batch_size, accuracy_metric, apply_gradient_masking=True)
        print(f"Batch {batch_start // batch_size + 1}/{len(train_images) // batch_size}, Accuracy: {accuracy}")


# Evaluate the model after gradient masking
masked_loss, masked_accuracy = loaded_model.evaluate(test_images, test_labels)
print(f'Model accuracy after gradient masking: {masked_accuracy * 100:.2f}%')


# Save the entire model after applying gradient masking
model_file_path_after_masking = r'C:\\Users\\eyian\\OneDrive\\Desktop\\model_after_masking.h5'
loaded_model.save(model_file_path_after_masking)


# Load the saved model for adversarial training
loaded_model_after_masking = tf.keras.models.load_model(model_file_path_after_masking)


epsilon_fgsm = 0.03


# Does a FGSM attack on the already trained model after gradient masking
test_images_adv_after_masking = fgsm_attack(loaded_model_after_masking, test_images, test_labels, epsilon_fgsm)
# Evaluates the accuracy of it
test_loss_adv_after_masking, test_accuracy_adv_after_masking = loaded_model_after_masking.evaluate(test_images_adv_after_masking, test_labels)


print(f"Test accuracy of the ResNet Model with FGSM attack after gradient masking: {test_accuracy_adv_after_masking}")
